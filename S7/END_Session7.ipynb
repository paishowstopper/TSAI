{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_Session7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQPHQuhX8P54LyQW9DUcNS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paishowstopper/TSAI/blob/main/S7/END_Session7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B6JDniYT5cp",
        "outputId": "7108d375-d086-411a-f9bc-e7175297fac1"
      },
      "source": [
        "!pip install torchtext==0.3.1\r\n",
        "!pip install google_trans_new"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20kB 29.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30kB 22.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 51kB 15.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 61kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.8.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.3.1) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed torchtext-0.3.1\n",
            "Collecting google_trans_new\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/7b/9f136106dc5824dc98185c97991d3cd9b53e70a197154dd49f7b899128f6/google_trans_new-1.1.9-py3-none-any.whl\n",
            "Installing collected packages: google-trans-new\n",
            "Successfully installed google-trans-new-1.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP8OuvYLHJMA",
        "outputId": "eefda92d-245f-4c31-b37a-6df8e4f11332"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\r\n",
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.corpus import wordnet\r\n",
        "import random\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import os, pickle\r\n",
        "import torch.optim as optim\r\n",
        "import spacy, math\r\n",
        "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\r\n",
        "import google_trans_new\r\n",
        "from google_trans_new import google_translator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIkhUXKgfVxh"
      },
      "source": [
        "def get_synonyms(word):\r\n",
        "  synonyms = []\r\n",
        "  for syn in wordnet.synsets(word): \r\n",
        "    for l in syn.lemmas():\r\n",
        "        synonyms.append(l.name())\r\n",
        "  if len(synonyms) > 0:\r\n",
        "    return random.choice(synonyms)\r\n",
        "  else:\r\n",
        "    return None"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4J-I_UkHzpV"
      },
      "source": [
        "def random_insertion(sentence, n=3): \r\n",
        "    new_sentence = sentence.split(' ')\r\n",
        "    words = remove_stopwords(sentence).split()\r\n",
        "    for _ in range(n):\r\n",
        "        new_synonym = get_synonyms(random.choice(words))\r\n",
        "        if new_synonym is not None:\r\n",
        "          new_sentence.insert(random.randrange(len(sentence)+1), new_synonym)\r\n",
        "        else:\r\n",
        "          new_synonym = ''        \r\n",
        "    return ' '.join(new_sentence)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF3WIXfJH2LY"
      },
      "source": [
        "def random_deletion(words, p=0.5): \r\n",
        "    if len(words) == 1: # return if single word\r\n",
        "        return words\r\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \r\n",
        "    if len(remaining) == 0: # if not left, sample a random word\r\n",
        "        return [random.choice(words)] \r\n",
        "    else:\r\n",
        "        return remaining"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHtZ9Bb7H6rG"
      },
      "source": [
        "def random_swap(sentence, n=5): \r\n",
        "    length = range(len(sentence))\r\n",
        "    if n > len(sentence):\r\n",
        "      n = len(sentence)\r\n",
        "    for _ in range(n):\r\n",
        "        idx1, idx2 = random.sample(length, 2)\r\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \r\n",
        "    return sentence"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BjGv6KWTreb"
      },
      "source": [
        "translator = google_translator()\r\n",
        "available_langs = list(google_trans_new.LANGUAGES.keys()) \r\n",
        "trans_lang = random.choice(available_langs) \r\n",
        "  \r\n",
        "def google_translate(sentence):\r\n",
        "  translations = translator.translate(sentence, lang_tgt=trans_lang) \r\n",
        "  t_text = ''.join([t for t in translations])\r\n",
        "  translations_en_random = translator.translate(t_text, lang_src=trans_lang, lang_tgt='en') \r\n",
        "  en_text = ''.join([t for t in translations_en_random])\r\n",
        "  return en_text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2puCsm09b99"
      },
      "source": [
        "df = pd.read_csv('tweets.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOXBPRFw9oBh",
        "outputId": "b55efe4c-b36d-470e-8c04-c4ddb5716487"
      },
      "source": [
        "# Manual Seed\r\n",
        "SEED = 43\r\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7dffae1990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slCcGivJfeKZ"
      },
      "source": [
        "split_length = math.ceil(len(df)*0.85)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2DLCCGHf9qj"
      },
      "source": [
        "train_df = df.iloc[:split_length]\r\n",
        "valid_df = df.iloc[split_length:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KebDiBYqouBN",
        "outputId": "9c284e1a-75b6-4f6b-dc2c-232ab4d68eb4"
      },
      "source": [
        "augmented_train_df= train_df.sample(n=25,random_state=SEED)\r\n",
        "augmented_train_df['tweets'] = augmented_train_df['tweets'].apply(google_translate)\r\n",
        "train_df.update(augmented_train_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:6397: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDqhgT5oWPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3929e288-d67e-4453-82b0-d9a623bfb843"
      },
      "source": [
        "augmented_train_df = train_df.sample(n=25, random_state=SEED)\r\n",
        "augmented_train_df['tweets'] = augmented_train_df['tweets'].apply(random_insertion)\r\n",
        "train_df.update(augmented_train_df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:6397: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQrl6CCUohIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba67728-4813-443d-f2d6-5779dd18ae5f"
      },
      "source": [
        "augmented_train_df = train_df.sample(n=25,random_state=SEED)\r\n",
        "augmented_train_df['tweets'] = augmented_train_df['tweets'].str.split().apply(random_deletion).apply(' '.join)\r\n",
        "train_df.update(augmented_train_df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:6397: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpVVkj8Po3_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fbad7f-d55a-41dc-8735-eff9b7fff516"
      },
      "source": [
        "augmented_train_df= train_df.sample(n=5,random_state=SEED)\r\n",
        "augmented_train_df['tweets'] = augmented_train_df['tweets'].str.split().apply(random_swap).apply(' '.join)\r\n",
        "train_df.update(augmented_train_df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:6397: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYdBLv6duFiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e779b80a-f88a-4cb0-9e55-5acddbf2400c"
      },
      "source": [
        "len(train_df)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6hy0kAr_3KR"
      },
      "source": [
        "Tweet = Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\r\n",
        "Label = LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU4adzKp_7LK"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUGzFeD_-hg"
      },
      "source": [
        "train_example = [Example.fromlist([train_df.tweets[i],train_df.labels[i]], fields) for i in range(train_df.shape[0])]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99_H2KJAhV0t"
      },
      "source": [
        "valid_example = [Example.fromlist([valid_df.tweets[i+split_length],valid_df.labels[i+split_length]], fields) for i in range(valid_df.shape[0])]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygdyWFgWAUpm"
      },
      "source": [
        "train = Dataset(train_example, fields)\r\n",
        "valid = Dataset(valid_example, fields)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdUpvKQWAf0x"
      },
      "source": [
        "Tweet.build_vocab(train)\r\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZVlPUCwBEom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473de054-bed7-4d48-fe04-1b83c547083a"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\r\n",
        "print('Size of label vocab : ', len(Label.vocab))\r\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\r\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4540\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1047), (':', 811), ('#', 780), ('.', 758), (',', 609), ('\"', 585), ('the', 552), ('RT', 524), ('?', 438), ('to', 410)]\n",
            "Labels :  defaultdict(<function _default_unk_index at 0x7f7dab96e050>, {0.0: 0, 1.0: 1, 2.0: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxczY66fBIpx"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtsD5SFsBKqG"
      },
      "source": [
        "train_iterator, valid_iterator = BucketIterator.splits((train, valid), batch_size = 32, \r\n",
        "                                                            sort_key = lambda x: len(x.tweets),\r\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZIi138eBSp1"
      },
      "source": [
        "with open('tokenizer.pkl', 'wb') as tokens: \r\n",
        "  pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-AjINFZHXgL"
      },
      "source": [
        "class classifier(nn.Module):\r\n",
        "    \r\n",
        "    # Define all the layers used in model\r\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\r\n",
        "        \r\n",
        "        super().__init__()          \r\n",
        "        \r\n",
        "        # Embedding layer\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "        \r\n",
        "        # LSTM layer\r\n",
        "        self.encoder = nn.LSTM(embedding_dim, \r\n",
        "                           hidden_dim, \r\n",
        "                           num_layers=n_layers, \r\n",
        "                           dropout=dropout,\r\n",
        "                           batch_first=True)\r\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\r\n",
        "        # try bidirectional and compare their performances\r\n",
        "        \r\n",
        "        # Dense layer\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "        \r\n",
        "    def forward(self, text, text_lengths):\r\n",
        "        \r\n",
        "        # text = [batch size, sent_length]\r\n",
        "        embedded = self.embedding(text)\r\n",
        "        # embedded = [batch size, sent_len, emb dim]\r\n",
        "      \r\n",
        "        # packed sequence\r\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\r\n",
        "        \r\n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\r\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\r\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\r\n",
        "    \r\n",
        "        # Hidden = [batch size, hid dim * num directions]\r\n",
        "        dense_outputs = self.fc(hidden)   \r\n",
        "        \r\n",
        "        # Final activation function softmax\r\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\r\n",
        "            \r\n",
        "        return output"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7znes_qHeLt"
      },
      "source": [
        "# Define hyperparameters\r\n",
        "size_of_vocab = len(Tweet.vocab)\r\n",
        "embedding_dim = 300\r\n",
        "num_hidden_nodes = 100\r\n",
        "num_output_nodes = 3\r\n",
        "num_layers = 2\r\n",
        "dropout = 0.2\r\n",
        "\r\n",
        "# Instantiate the model\r\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU2rzUemHgKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c53710e-6a1a-46e0-f4ce-7440a408a69a"
      },
      "source": [
        "print(model)\r\n",
        "\r\n",
        "#No. of trianable parameters\r\n",
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "    \r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4540, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,603,903 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2IDb1-SHiUI"
      },
      "source": [
        "\r\n",
        "# define optimizer and loss\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# define metric\r\n",
        "def binary_accuracy(preds, y):\r\n",
        "    #round predictions to the closest integer\r\n",
        "    _, predictions = torch.max(preds, 1)\r\n",
        "    \r\n",
        "    correct = (predictions == y).float() \r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "    return acc\r\n",
        "    \r\n",
        "# push to cuda if available\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWMuEYZZHmfR"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "    \r\n",
        "    # initialize every epoch \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    # set the model in training phase\r\n",
        "    model.train()  \r\n",
        "    \r\n",
        "    for batch in iterator:\r\n",
        "        \r\n",
        "        # resets the gradients after every batch\r\n",
        "        optimizer.zero_grad()   \r\n",
        "        \r\n",
        "        # retrieve text and no. of words\r\n",
        "        tweet, tweet_lengths = batch.tweets   \r\n",
        "        \r\n",
        "        # convert to 1D tensor\r\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \r\n",
        "        \r\n",
        "        # compute the loss\r\n",
        "        loss = criterion(predictions, batch.labels)        \r\n",
        "        \r\n",
        "        # compute the binary accuracy\r\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \r\n",
        "        \r\n",
        "        # backpropage the loss and compute the gradients\r\n",
        "        loss.backward()       \r\n",
        "        \r\n",
        "        # update the weights\r\n",
        "        optimizer.step()      \r\n",
        "        \r\n",
        "        # loss and accuracy\r\n",
        "        epoch_loss += loss.item()  \r\n",
        "        epoch_acc += acc.item()    \r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_68yCZ-xHoY0"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    # initialize every epoch\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    # deactivating dropout layers\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    # deactivates autograd\r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in iterator:\r\n",
        "        \r\n",
        "            # retrieve text and no. of words\r\n",
        "            tweet, tweet_lengths = batch.tweets\r\n",
        "            \r\n",
        "            # convert to 1d tensor\r\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\r\n",
        "            \r\n",
        "            # compute loss and accuracy\r\n",
        "            loss = criterion(predictions, batch.labels)\r\n",
        "            acc = binary_accuracy(predictions, batch.labels)\r\n",
        "            \r\n",
        "            # keep track of loss and accuracy\r\n",
        "            epoch_loss += loss.item()\r\n",
        "            epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aae9br0AHqQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ac12ac-4108-4826-a5a6-41e74b72675b"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "     \r\n",
        "    # train the model\r\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    \r\n",
        "    # evaluate the model\r\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    # save the best model\r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "    \r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.034 | Train Acc: 66.55%\n",
            "\t Val. Loss: 1.018 |  Val. Acc: 68.45% \n",
            "\n",
            "\tTrain Loss: 0.968 | Train Acc: 71.45%\n",
            "\t Val. Loss: 0.970 |  Val. Acc: 68.90% \n",
            "\n",
            "\tTrain Loss: 0.909 | Train Acc: 72.04%\n",
            "\t Val. Loss: 0.929 |  Val. Acc: 67.56% \n",
            "\n",
            "\tTrain Loss: 0.856 | Train Acc: 73.48%\n",
            "\t Val. Loss: 0.884 |  Val. Acc: 68.45% \n",
            "\n",
            "\tTrain Loss: 0.815 | Train Acc: 76.01%\n",
            "\t Val. Loss: 0.857 |  Val. Acc: 72.02% \n",
            "\n",
            "\tTrain Loss: 0.789 | Train Acc: 77.96%\n",
            "\t Val. Loss: 0.844 |  Val. Acc: 72.02% \n",
            "\n",
            "\tTrain Loss: 0.770 | Train Acc: 78.72%\n",
            "\t Val. Loss: 0.839 |  Val. Acc: 73.36% \n",
            "\n",
            "\tTrain Loss: 0.753 | Train Acc: 80.32%\n",
            "\t Val. Loss: 0.837 |  Val. Acc: 74.26% \n",
            "\n",
            "\tTrain Loss: 0.739 | Train Acc: 81.76%\n",
            "\t Val. Loss: 0.831 |  Val. Acc: 73.81% \n",
            "\n",
            "\tTrain Loss: 0.727 | Train Acc: 83.53%\n",
            "\t Val. Loss: 0.827 |  Val. Acc: 74.70% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVwpwDX6HuJN"
      },
      "source": [
        "#load weights and tokenizer\r\n",
        "\r\n",
        "path='./saved_weights.pt'\r\n",
        "model.load_state_dict(torch.load(path));\r\n",
        "model.eval();\r\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\r\n",
        "tokenizer = pickle.load(tokenizer_file)\r\n",
        "\r\n",
        "#inference \r\n",
        "\r\n",
        "nlp = spacy.load('en')\r\n",
        "\r\n",
        "def classify_tweet(tweet):\r\n",
        "    \r\n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\r\n",
        "    \r\n",
        "    # tokenize the tweet \r\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \r\n",
        "    # convert to integer sequence using predefined tokenizer dictionary\r\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \r\n",
        "    # compute no. of words        \r\n",
        "    length = [len(indexed)]\r\n",
        "    # convert to tensor                                    \r\n",
        "    tensor = torch.LongTensor(indexed).to(device)   \r\n",
        "    # reshape in form of batch, no. of words           \r\n",
        "    tensor = tensor.unsqueeze(1).T  \r\n",
        "    # convert to tensor                          \r\n",
        "    length_tensor = torch.LongTensor(length)\r\n",
        "    # Get the model prediction                  \r\n",
        "    prediction = model(tensor, length_tensor)\r\n",
        "\r\n",
        "    _, pred = torch.max(prediction, 1) \r\n",
        "    \r\n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoDbl5WEHyer",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05d48c24-aada-4dcd-f7ad-41f85ec4e158"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}